{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit235c09e77a3a4be4a0fbcd79d7c7728e",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 MNIST 手寫數字資料讀進來\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# mnist 的load_data()會回傳已經先分割好的training data 和 testing data\n",
    "# 並且將每個 pixel 的值從 Int 轉成 floating point 同時做normalize(這是很常見的preprocessing)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "60000\n(28, 28)\n"
    }
   ],
   "source": [
    "print(len(x_train)) # training data 總共有60000張圖片\n",
    "print(x_train[0].shape) # 每張圖片（拿第一張當樣本）大小為 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始搭建model\n",
    "# 利用 \"Sequential\" 把每層 layer 疊起來\n",
    "\n",
    "# input 大小為 28 x 28\n",
    "\n",
    "# 最後的 Dense(10) 且 activation 用 softmax\n",
    "# 代表最後 output 為 10 個 class （0~9）的機率\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# model每層定義好後需要經過compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy', # 交叉熵的一種\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\nEpoch 1/5\n60000/60000 [==============================] - 3s 49us/sample - loss: 0.0389 - accuracy: 0.9868\nEpoch 2/5\n60000/60000 [==============================] - 3s 46us/sample - loss: 0.0384 - accuracy: 0.9872\nEpoch 3/5\n60000/60000 [==============================] - 3s 45us/sample - loss: 0.0330 - accuracy: 0.9887\nEpoch 4/5\n60000/60000 [==============================] - 3s 44us/sample - loss: 0.0340 - accuracy: 0.9885\nEpoch 5/5\n60000/60000 [==============================] - 3s 49us/sample - loss: 0.0317 - accuracy: 0.9896\n**************************************************\n10000/1 - 0s - loss: 0.0366 - accuracy: 0.9800\n"
    },
    {
     "data": {
      "text/plain": "[0.07321494583048334, 0.98]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將搭好的 model 去 fit 我們的 training data\n",
    "# 並evaluate 在 testing data 上\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "print('*'*50)\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}